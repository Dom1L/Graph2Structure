{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import g2s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Featurization\n",
    "To train Graph-To-Structure, you need a bond order and distances matrix and the corresponding nuclear charges of the system.\n",
    "\n",
    "You can get a bond order matrix either through SMILES/SMARTS/SELFIES or you can use some of the graph extraction tools explained\n",
    "in the graph extraction tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_mols = np.load('../tests/test_files/test_molecules.npz', allow_pickle=True)\n",
    "bond_order_matrix, distances, nuclear_charges = test_mols['adj'], test_mols['distances'], test_mols['nuclear_charges']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step requires the featurization of our molecules. \n",
    "\n",
    "Since the example molecules are of different sizes, we have to apply zero padding\n",
    "to the representation as well as the distance matrix! \n",
    "\n",
    "For that we need to know the largest number of heavy atoms in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_natoms = max([len(np.where(np.array(z) != 1)[0]) for z in nuclear_charges])\n",
    "print(f'Largest molecule has size: {max_natoms}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important step in G2S is the separation of the heavy-atom scaffold from all the hydrogens. \n",
    "\n",
    "Heavy atom distances are predicted separately from hydrogens, for which reason these two are separate machine learning problems in G2S.\n",
    "\n",
    "Disclaimer: In case a molecule has less than 4 heavy atoms, atoms are not separated. (Check the first molecule in the set!)\n",
    "\n",
    "You can decide for yourself how to add hydrogens later on. Either through G2S or by using tools like RDkit or Open Babel.\n",
    "\n",
    "We featurize the heavy atom scaffold using the bond length representation, which is the sum of the bond lengths on the shortes path between two atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Graph compound class\n",
    "gc = g2s.GraphCompound(bond_order_matrix[3], nuclear_charges[3], distances[3])\n",
    "\n",
    "# Filter heavy atoms\n",
    "gc.filter_atoms('heavy')\n",
    "\n",
    "# Compute Bond Length matrix for the heavy atom scaffold\n",
    "# To ensure permutational invariance, the matrix is sorted by its row-norm\n",
    "gc.generate_bond_length(size=max_natoms, sorting='row-norm')\n",
    "print('Zero-padded, flattened bond length representation:')\n",
    "print(gc.representation)\n",
    "\n",
    "# For the prediction of hydrogens, compute a local hydrogen matrix\n",
    "gc.generate_local_hydrogen_matrix()\n",
    "\n",
    "print('Local hydrogen environment representation:')\n",
    "print(gc.hydrogen_representations)\n",
    "print('Closest 4 heavy atom to hydrogen distances:')\n",
    "print('Last value is the H-H distance in case multiple hydrogens are attached.')\n",
    "print(gc.hydrogen_heavy_distances)\n",
    "print('Central heavy atom, hydrogen and neighbour indices')\n",
    "print(gc.heavy_hydrogen_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we repeat the procedure for all molecules in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy Atom Stuff\n",
    "representations = []\n",
    "padded_nuclear_charges = []\n",
    "padded_distances = []\n",
    "adj_mat = []\n",
    "nucl_ch = []\n",
    "\n",
    "# Hydrogen Stuff\n",
    "local_hydrogen = []\n",
    "heavy_hydrogen_mapping = []\n",
    "hydrogen_heavy_dist = []\n",
    "for bo, dist, nc, in zip(bond_order_matrix, distances, nuclear_charges):\n",
    "    \n",
    "    # Initialize the Graph compound class\n",
    "    gc = g2s.GraphCompound(bo, nc, dist)\n",
    "    \n",
    "    # Filter heavy atoms\n",
    "    gc.filter_atoms('heavy')\n",
    "    \n",
    "    # Compute Bond Length matrix for the heavy atom scaffold\n",
    "    # To ensure permutational invariance, the matrix is sorted by its row-norm\n",
    "    gc.generate_bond_length(size=max_natoms, sorting='row-norm')\n",
    "    \n",
    "    # For the prediction of hydrogens, compute a local hydrogen matrix\n",
    "    gc.generate_local_hydrogen_matrix()\n",
    "    \n",
    "    representations.append(gc.representation)\n",
    "    padded_nuclear_charges.append(gc.nuclear_charges)\n",
    "    padded_distances.append(gc.distances)\n",
    "    adj_mat.append(gc.full_adjacency_matrix)\n",
    "    nucl_ch.append(gc.full_nuclear_charges)\n",
    "\n",
    "    local_hydrogen.append(gc.hydrogen_representations)\n",
    "    heavy_hydrogen_mapping.append(gc.heavy_hydrogen_mapping)\n",
    "    hydrogen_heavy_dist.append(gc.hydrogen_heavy_distances)\n",
    "\n",
    "representations = np.array(representations)\n",
    "padded_nuclear_charges = np.array(padded_nuclear_charges)\n",
    "padded_distances = np.array(padded_distances)\n",
    "local_hydrogen = np.array(local_hydrogen)\n",
    "heavy_hydrogen_mapping = np.array(heavy_hydrogen_mapping)\n",
    "hydrogen_heavy_dist = np.array(hydrogen_heavy_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "In this example, we use Kernel Ridge Regression (KRR) for the learning of distance matrices.\n",
    "\n",
    "Specifically, we use a single kernel machine per distance matrix element.\n",
    "\n",
    "Since the representation and therefore the kernel matrix is independent of the distance matrix elements, only a singel kernel inversion has to be performed, which leaves \n",
    "n dot products to perform (for n distance matrix elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sigma = 32\n",
    "kernel_lambda = 1e-5\n",
    "\n",
    "train_kernel = g2s.krr.laplacian_kernel(representations, representations, 32)\n",
    "train_kernel[np.diag_indices_from(train_kernel)] += 1e-5\n",
    "alphas = g2s.krr.train_multikernel(train_kernel, padded_distances)\n",
    "\n",
    "pred_distances = g2s.krr.predict_distances(train_kernel, alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more numerical stability, instead of the multikernel approach a standard cholesky decomposition can also be performed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cho_alphas = g2s.krr.train_cholesky(train_kernel, padded_distances)\n",
    "cho_pred_distances = g2s.krr.predict_distances(train_kernel, cho_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar logic applies to the learning of local heavy atom to hydrogen distances.\n",
    "Don't forget to stack your local environments before training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(local_hydrogen.shape)\n",
    "hydrogen_representation = np.vstack(local_hydrogen)\n",
    "hydrogen_distances = np.vstack(hydrogen_heavy_dist)\n",
    "print(hydrogen_representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kernel = g2s.krr.laplacian_kernel(hydrogen_representation, hydrogen_representation, 32)\n",
    "train_kernel[np.diag_indices_from(train_kernel)] += 1e-7\n",
    "hydro_alphas = g2s.krr.train_multikernel(train_kernel, hydrogen_distances)\n",
    "\n",
    "pred_hydrogen_distances = g2s.krr.predict_distances(train_kernel, hydro_alphas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry Reconstruction, Solving the Distance Geometry Problem\n",
    "\n",
    "To convert the predicted distance matrices, we have to solve the Distance Geometry Problem!\n",
    "\n",
    "This problem deals with embedding points in a space, given a specified distance boundary (our predicted distances matrix).\n",
    "\n",
    "In G2S, we use a software called DGSOL, which solves the DGP even for noisy and/or sparse distance matrices (such as obtained from macromolecular NMR experiments).\n",
    "\n",
    "Make sure you have added the dgsol binary to your $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to filter non-zero distances from the zero-padding we had to apply for training!\n",
    "nz_pred_distances = g2s.utils.filter_nonzero_distances(pred_distances, padded_nuclear_charges)\n",
    "dgsol = g2s.dgeom.DGSOL(nz_pred_distances, padded_nuclear_charges, vectorized_input=False)\n",
    "dgsol.solve_distance_geometry('./test_molecules')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can access the coordinates using `dgsol.coords`\n",
    "\n",
    "If you want to write xyz's files to disc, you can use some helper functions in G2S such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2s.utils import write_xyz\n",
    "write_xyz('./test0.xyz', dgsol.coords[0], dgsol.nuclear_charges[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the hydrogens are still missing! Let's add them shall we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2s.dgeom import hydrogen_lebedev_reconstruction\n",
    "from g2s.utils import combine_heavy_hydrogen_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function hydrogen_lebedev_reconstruction constructs a lebedev sphere around a central heavy atom and \n",
    "places hydrogens on top of this sphere given the distance constraints we have predicted with our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(sorted(glob('./test_molecules/*'))):\n",
    "    if heavy_hydrogen_mapping[i].size > 0.:\n",
    "        h_coords = hydrogen_lebedev_reconstruction(dgsol.coords[i], hydrogen_heavy_dist[i], heavy_hydrogen_mapping[i])\n",
    "        heavy_c, all_nc = combine_heavy_hydrogen_coords(dgsol.coords[i], h_coords, padded_nuclear_charges[i])\n",
    "        write_xyz(f'{e}/dgsol_h.xyz', heavy_c, all_nc)\n",
    "    else:\n",
    "        write_xyz(f'{e}/dgsol_h.xyz', dgsol.coords[i], dgsol.nuclear_charges[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your molecules at `./test_molecules/`!\n",
    "\n",
    "If you `pip install py3Dmol` you can visualize molecules in juypter notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import py3Dmol\n",
    "# with open('./test_molecules/0001/dgsol_h.xyz', 'r') as infile:\n",
    "#     xyz = infile.readlines()\n",
    "# xyz = ''.join(xyz)\n",
    "# xyzview = py3Dmol.view(width=400,height=400)\n",
    "# xyzview.addModel(xyz,'xyz')\n",
    "# xyzview.setStyle({'stick':{'colorscheme':'cyanCarbon'}})\n",
    "# xyzview.zoomTo()\n",
    "# xyzview.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The G2S package also provides an interface to saturate a molecule using rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2s.dgeom.rdkit import embed_hydrogens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, e in enumerate(sorted(glob('./test_molecules/*'))):\n",
    "    if heavy_hydrogen_mapping[i].size > 0.:\n",
    "        try:\n",
    "            embedded_coords, embedded_nuclear_charges, new_adj_mat = embed_hydrogens(adj_mat[i], nucl_ch[i], dgsol.coords[i])\n",
    "        except Exception as err:\n",
    "            print(f'Structure number {i} failed in RDkit for the following reason:')\n",
    "            print(err)\n",
    "            print('------------------')\n",
    "            continue\n",
    "        write_xyz(f'{e}/rdkit.xyz', embedded_coords, embedded_nuclear_charges)\n",
    "    else:\n",
    "        write_xyz(f'{e}/rdkit.xyz', dgsol.coords[i], dgsol.nuclear_charges[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDkit in general often struggles with Nitrogen's (as you see in the example above). \n",
    "\n",
    "Be careful when you use this functionality! RDkit might crash!\n",
    "\n",
    "(Which is another the reason to use G2S instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
